# -*- coding: utf-8 -*-
"""Multilingual Spam Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vVKAv94LT02zq_JQuZ5iKzw3WG2bbgio

## Pipelining
Data Importing and Cleaning -> Message Preprocessing -> Label Encoding -> Embeddings from Multilingual Model -> Using TPOT to find best Pipeline -> Prediction
"""

import pandas as pd
import seaborn as sns
import re
import matplotlib.pyplot as plt

"""## Reading the data"""

from google.colab import drive
drive.mount('/content/drive')

file_path = '/content/drive/My Drive/spam/spam.csv'
df=pd.read_csv(file_path,encoding="Latin-1")
df = df[['v1','v2']]
df.set_axis(['Label', 'Message'], axis=1, inplace=True)

"""### Exploring the data"""

df.head()

df.Label.unique()

df.isnull().sum() ## checking for null values

sns.set_style('whitegrid')
sns.countplot(x='Label',data=df)

# Assuming df is your DataFrame with the 'Label' column
sns.set_style('whitegrid')
ax = sns.countplot(x='Label', data=df)

# Add counts on top of the bars
for p in ax.patches:
    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='center', xytext=(0, 10), textcoords='offset points')

# Add total count annotation below "Label" bars
total_count = len(df)
ax.annotate(f'Total: {total_count}', (0.5, -0.3), ha='center', va='center', xytext=(0, 0), textcoords='offset points', fontweight='bold')

plt.show()

"""### Preprocessing the data"""

def preprocessing(text):
    #Changing text to lowercase ,removing extra spaces and cleaning the text.
    text= text.lower().strip()

    text=re.sub('[^a-zA-Z]',' ',text)

    text=re.sub(' +', ' ', text)
    return text

df['Message']=df['Message'].apply(preprocessing)

df.head()

#Encoding 0 for ham and 1 for Spam
from sklearn.preprocessing import LabelEncoder

LE=LabelEncoder()
LE.fit(df["Label"])

df["Label"]=LE.transform(df["Label"])

df

sns.set_style('whitegrid')
sns.countplot(x='Label',data=df)

"""### Converting messages to Embeddings"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install sentence-transformers

from sentence_transformers import SentenceTransformer

Encoder = SentenceTransformer('distiluse-base-multilingual-cased') # import the same model

embeddings=Encoder.encode(df["Message"]) # Encode text into vectors

len(embeddings)

embeddings[0]

print(embeddings[0].shape)

"""## Preparing the train and test data"""

x=embeddings
y=df["Label"].values

from sklearn.model_selection import train_test_split

X_train,X_test,y_train,y_test= train_test_split(x,y,test_size=0.20,random_state=42)

print("Training set of X and y-->",len(X_train),len(y_train))
print("Test set of X and y-->",len(X_test),len(y_test))

"""## Apply Classification algorithm

TPOT
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install tpot

from tpot import TPOTClassifier

tpot = TPOTClassifier(generations=5, population_size=20, random_state=42, verbosity=2)

tpot.fit(X_train, y_train)
accuracy = tpot.score(X_test, y_test)
print(f"Accuracy: {accuracy}")

"""### Confusion Matrix

"""

y_pred = tpot.predict(X_test)

# Create a confusion matrix
conf_mat = confusion_matrix(y_test, y_pred)
print(conf_mat)

"""## Visualize the Confusion matrix"""

class_labels = ["ham", "spam"]
# Create the confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)

# Plot the confusion matrix using seaborn
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=class_labels, yticklabels=class_labels)
plt.title("Confusion Matrix")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()

"""#Classification Report"""

from sklearn.metrics import classification_report

y_pred = tpot.predict(X_test)

# Generate the classification report
report = classification_report(y_test, y_pred, target_names=class_labels)

# Print the classification report
print("Classification Report:\n", report)

"""## Predicting for new input"""

# We have trained our model 0 for ham and 1 for Spam
def prediction(predict_text):
    predict_data=Encoder.encode([predict_text])
    if tpot.predict(predict_data)[0]>0:
        return "Spam"
    else:
        return "Ham"

prediction("Congratulations ur awarded 500 of CD vouchers or 125gift guaranteed & Free entry 2 100 wkly draw txt MUSIC to 87066 TnCs www.Ldew.com1win150ppmx3age16")

prediction("आपको 500 सीडी वाउचर या 125 उपहार की गारंटी के साथ बधाई और मुफ्त प्रवेश 2 100 साप्ताहिक ड्रा टीएक्सटी म्यूजिक से 87066 टीएनसीएस www.Ldew.com1win150ppmx3age16")

prediction("તમને 500 CD વાઉચર અથવા 125 ગિફ્ટ ગેરંટી અને ફ્રી એન્ટ્રી 87066 TnCs પર 100 અઠવાડિયામાં ડ્રો txt MUSIC આપવા બદલ અભિનંદન www.Ldew.com1win150ppmx3age16")